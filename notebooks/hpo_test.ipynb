{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f207d9ab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import (AutoModelForSequenceClassification, AutoTokenizer,\n",
    "                          Trainer, TrainingArguments)\n",
    "\n",
    "from models.hugging_face_vit import ViTForImageClassification, ViTConfig\n",
    "from transformers import BertTokenizer, GPT2Tokenizer, ViTFeatureExtractor\n",
    "from mup import set_base_shapes, make_base_shapes\n",
    "import numpy as np\n",
    "import torch\n",
    "from functools import partial\n",
    "from time import time\n",
    "from ray import tune\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117b0ff6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def make_bsh(filename=None):\n",
    "    base_config = ViTConfig(\n",
    "      hidden_size= 256,\n",
    "      intermediate_size=256,\n",
    "      num_attention_heads=4,\n",
    "      activation_function='relu',\n",
    "      num_hidden_layers=2,\n",
    "      num_labels=3,\n",
    "    )\n",
    "    delta_config = ViTConfig(\n",
    "      num_attention_heads=5,\n",
    "      intermediate_size=200,\n",
    "      hidden_size=200,\n",
    "      activation_function='relu',\n",
    "      num_hidden_layers=2,\n",
    "      num_labels=3,\n",
    "    )\n",
    "    base_model = ViTForImageClassification(config=base_config)\n",
    "    delta_model = ViTForImageClassification(config=delta_config)\n",
    "    base_shapes = make_base_shapes(base_model, delta_model, savefile=filename)\n",
    "    return base_shapes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0524f185",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_name_or_path = 'google/vit-base-patch16-224-in21k'\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(model_name_or_path)\n",
    "\n",
    "ds = load_dataset('beans')\n",
    "\n",
    "def transform(example_batch):\n",
    "    # Take a list of PIL images and turn them to pixel values\n",
    "    inputs = feature_extractor([x for x in example_batch['image']], return_tensors='pt')\n",
    "\n",
    "    # Don't forget to include the labels!\n",
    "    inputs['labels'] = example_batch['labels']\n",
    "    return inputs\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
    "        'labels': torch.tensor([x['labels'] for x in batch])\n",
    "    }\n",
    "\n",
    "prepared_ds = ds.with_transform(transform)\n",
    "labels = ds['train'].features['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe51b8b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(width, base_shape=None, mup=True, readout_zero_init=True, query_zero_init=True, vary_nhead=False, n_labels=3):\n",
    "    width = int(width)\n",
    "    nhead = 4\n",
    "    if vary_nhead:\n",
    "        nhead = int(4 * width / 252)\n",
    "    def f():\n",
    "        config = ViTConfig(\n",
    "            hidden_size=width,\n",
    "            num_labels=n_labels,\n",
    "            intermediate_size=width,\n",
    "            num_attention_heads=nhead,\n",
    "            num_hidden_layers=2,\n",
    "            attn_mult=8 if mup else None,\n",
    "        )\n",
    "        model = ViTForImageClassification(config=config)\n",
    "\n",
    "        if mup:\n",
    "          set_base_shapes(model, base_shape)\n",
    "        else:\n",
    "          set_base_shapes(model, None)\n",
    "\n",
    "        model.apply(\n",
    "          partial(model._init_weights,\n",
    "                  readout_zero_init=readout_zero_init,\n",
    "                  query_zero_init=query_zero_init,\n",
    "                  ))\n",
    "        return model\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cb9d4a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from mup.optim import MuAdamW\n",
    "\n",
    "class MuTrainer(Trainer):\n",
    "    def create_optimizer_and_scheduler(self, num_training_steps: int):\n",
    "        \"\"\"\n",
    "        Setup the optimizer and the learning rate scheduler.\n",
    "\n",
    "        We provide a reasonable default that works well. If you want to use something else, you can pass a tuple in the\n",
    "        Trainer's init through `optimizers`, or subclass and override this method (or `create_optimizer` and/or\n",
    "        `create_scheduler`) in a subclass.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.optimizer = MuAdamW(self.model.parameters(), lr=5e-5)\n",
    "        self.create_scheduler(num_training_steps=num_training_steps, optimizer=self.optimizer)\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "def compute_metrics(p):\n",
    "    return metric.compute(predictions=np.argmax(p.predictions, axis=1), references=p.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d2c125",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tune_config = {\n",
    "    \"learning_rate\": tune.uniform(1e-3, 1e-7),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918d2158",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    \"test\", evaluation_strategy=\"steps\", eval_steps=500, disable_tqdm=True, remove_unused_columns=False, learning_rate=5e-5)\n",
    "\n",
    "bests = {}\n",
    "ts = time()\n",
    "vary_nhead = False\n",
    "widths = 2**np.arange(6, 11)\n",
    "base_shape = make_bsh()\n",
    "for mup in [True, False]:\n",
    "    models = {width: get_model(width, base_shape=base_shape, mup=mup, vary_nhead=vary_nhead, n_labels=labels.num_classes) for width in widths}\n",
    "    trainclass = MuTrainer if mup else Trainer\n",
    "    for width, model in models.items():\n",
    "        trainer = trainclass(\n",
    "            model_init=model,\n",
    "            args=training_args,\n",
    "            data_collator=collate_fn,\n",
    "            compute_metrics=compute_metrics,\n",
    "            train_dataset=prepared_ds[\"train\"],\n",
    "            eval_dataset=prepared_ds[\"validation\"],\n",
    "            tokenizer=feature_extractor,\n",
    "    #         optimizers=(AdamW,torch.optim.lr_scheduler.StepLR)\n",
    "        )\n",
    "        best = trainer.hyperparameter_search(\n",
    "            backend=\"ray\",\n",
    "            n_trials=10, # number of trials\n",
    "            name=f\"{ts}_{'mup' if mup else 'sp'}_test_width_{width}\",\n",
    "            hp_space=lambda _: tune_config\n",
    "        )\n",
    "        bests[width] = best\n",
    "    plt.title(f\"{'mup' if mup else 'sp'} test\")\n",
    "    plt.plot(bests.keys(), [b.hyperparameters['learning_rate'] for b in bests.values()])\n",
    "    plt.xlabel('width')\n",
    "    plt.ylabel('lr')\n",
    "   plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![title](./sp_test.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: unknown file attribute: _\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "![title](./mup_test.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}